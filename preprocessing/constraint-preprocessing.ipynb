{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "\n",
    "# import faiss\n",
    "from tenacity import retry, wait_random_exponential, before_sleep_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONTOLOGY_MAPPINGS_DIR = \"../utils/ontology_mappings/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting relation names and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting labels and data types of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP_2_LABEL = {}\n",
    "PROP_2_DATA_TYPE = {}\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "# SPARQL query for properties with data types: Item, Quantity, Point in time\n",
    "query = \"\"\"\n",
    "SELECT ?property ?propertyLabel ?typeLabel WHERE {\n",
    "  ?property a wikibase:Property .\n",
    "  ?property wikibase:propertyType ?type .\n",
    "  \n",
    "  VALUES ?type { wikibase:WikibaseItem wikibase:Quantity wikibase:Time }\n",
    "  \n",
    "  BIND(\n",
    "    IF(?type = wikibase:WikibaseItem, \"Item\",\n",
    "      IF(?type = wikibase:Quantity, \"Quantity\",\n",
    "        IF(?type = wikibase:Time, \"Point in time\", \"Unknown\")\n",
    "      )\n",
    "    ) AS ?typeLabel\n",
    "  )\n",
    "  \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sparql.setQuery(query)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "try:\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        prop = result[\"property\"][\"value\"].split(\"/\")[-1]\n",
    "        label = result.get(\"propertyLabel\", {}).get(\"value\", \"No label\")\n",
    "        data_type = result.get(\"typeLabel\", {}).get(\"value\", \"Unknown\")\n",
    "\n",
    "        PROP_2_LABEL[prop] = label\n",
    "        PROP_2_DATA_TYPE[prop] = data_type        \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error executing SPARQL query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PROP_2_LABEL), len(PROP_2_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(PROP_2_DATA_TYPE.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2data_type.json\", 'w') as f:\n",
    "    json.dump(PROP_2_DATA_TYPE, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2label.json\", 'w') as f:\n",
    "    json.dump(PROP_2_LABEL, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting relation aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(PROP_2_LABEL.keys())), len(set(PROP_2_LABEL.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "def get_property_aliases(property_id):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?alias WHERE {{\n",
    "      wd:{property_id} skos:altLabel ?alias .\n",
    "      FILTER (lang(?alias) = \"en\")\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    aliases = [result[\"alias\"][\"value\"] for result in results[\"results\"][\"bindings\"]]\n",
    "    return aliases\n",
    "\n",
    "PROP2ALIASES = {}\n",
    "\n",
    "for property_id in tqdm(PROP_2_LABEL.keys()):\n",
    "    PROP2ALIASES[property_id] = get_property_aliases(property_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_set = set()\n",
    "alias_list = []\n",
    "for prop, aliases in PROP2ALIASES.items():\n",
    "    alias_set.update(aliases)\n",
    "    alias_list.extend(aliases)\n",
    "print(len(alias_set), len(alias_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in PROP_2_LABEL:\n",
    "    print(PROP_2_LABEL[prop], PROP2ALIASES[prop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2label.json\", 'w') as f:\n",
    "    json.dump(PROP_2_LABEL, f)\n",
    "\n",
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2aliases.json\", 'w') as f:\n",
    "    json.dump(PROP2ALIASES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2label.json\", 'r') as f:\n",
    "    PROP_2_LABEL = json.load(f)\n",
    "\n",
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2aliases.json\", 'r') as f:\n",
    "    PROP2ALIASES = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting subject and value constraints of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "def get_constraints(property_id):\n",
    "    \"\"\"Retrieve value-type and subject-type constraints for a specified Wikidata property.\"\"\"\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?constraintType ?entity ?entityLabel WHERE {{\n",
    "      VALUES ?property {{ wd:{property_id} }}  \n",
    "\n",
    "      ?property p:P2302 ?statement.  # Property constraints\n",
    "      ?statement ps:P2302 ?constraintEntity.  # Constraint type\n",
    "\n",
    "      VALUES ?constraintEntity {{ wd:Q21510865 wd:Q21503250 }}  # Value-type & Subject-type constraints\n",
    "\n",
    "      ?statement pq:P2308 ?entity.  # The constrained entity type (allowed type)\n",
    "\n",
    "      BIND(\n",
    "        IF(?constraintEntity = wd:Q21510865, \"Value-type constraint\", \"Subject type constraint\")\n",
    "        AS ?constraintType\n",
    "      )\n",
    "    }}\n",
    "    \"\"\"\n",
    "    # SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    constraints = {\"Value-type constraint\": [], \"Subject type constraint\": []}\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        constraints[result[\"constraintType\"][\"value\"]].append(result[\"entity\"][\"value\"].split(\"/\")[-1])\n",
    "\n",
    "    return constraints\n",
    "\n",
    "# Example usage:\n",
    "property_id = \"P40\"  # Replace with any Wikidata property ID\n",
    "constraints = get_constraints(property_id)\n",
    "\n",
    "print(constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_dict = {}\n",
    "\n",
    "for prop in tqdm(PROP_2_LABEL.keys()):\n",
    "    constraint_dict[prop] = get_constraints(prop)\n",
    "    time.sleep(0.1)\n",
    "len(constraint_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2data_type.json\", 'r') as f:\n",
    "    PROP_2_DATA_TYPE = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROP_2_DATA_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_dict['P2294']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_constraint = []\n",
    "for prop in constraint_dict:\n",
    "    if len(constraint_dict[prop][\"Value-type constraint\"]) == 0 and len(constraint_dict[prop][\"Subject type constraint\"]) == 0:\n",
    "            wo_constraint.append(prop)\n",
    "len(wo_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity_props = []\n",
    "time_props = []\n",
    "other_props = []\n",
    "for prop in wo_constraint:\n",
    "    if PROP_2_DATA_TYPE[prop] == \"Quantity\": \n",
    "        quantity_props.append(prop)\n",
    "    elif PROP_2_DATA_TYPE[prop] == \"Point in time\": \n",
    "        time_props.append(prop)\n",
    "    else:\n",
    "        other_props.append(prop)\n",
    "        \n",
    "        # print(PROP_2_LABEL[prop])\n",
    "len(time_props), len(quantity_props), len(other_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((28, 295, 258))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in constraint_dict:\n",
    "    if PROP_2_DATA_TYPE[prop] == \"Point in time\":\n",
    "        constraint_dict[prop][\"Value-type constraint\"].append('Q186408')\n",
    "\n",
    "    elif PROP_2_DATA_TYPE[prop] == 'Quantity':\n",
    "        constraint_dict[prop][\"Value-type constraint\"].append('Q309314')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_constraint = []\n",
    "for prop in constraint_dict:\n",
    "    if len(constraint_dict[prop][\"Value-type constraint\"]) == 0 and len(constraint_dict[prop][\"Subject type constraint\"]) == 0:\n",
    "            wo_constraint.append(prop)\n",
    "len(wo_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_constraint = []\n",
    "for prop in constraint_dict:\n",
    "    if len(constraint_dict[prop][\"Value-type constraint\"]) == 0:\n",
    "            constraint_dict[prop][\"Value-type constraint\"] = ['ANY']\n",
    "    if len(constraint_dict[prop][\"Subject type constraint\"]) == 0:\n",
    "        constraint_dict[prop][\"Subject type constraint\"] = ['ANY']\n",
    "len(wo_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_constraint = []\n",
    "for prop in constraint_dict:\n",
    "    if len(constraint_dict[prop][\"Value-type constraint\"]) == 0 and len(constraint_dict[prop][\"Subject type constraint\"]) == 0:\n",
    "            wo_constraint.append(prop)\n",
    "len(wo_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+'prop2constraints.json', 'w') as f:\n",
    "    json.dump(constraint_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+'prop2constraints.json', 'r') as f:\n",
    "    constraint_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"prop2data_type.json\", 'r') as f:\n",
    "    PROP_2_DATA_TYPE = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colecting entities' metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = set()\n",
    "for prop, constraint in constraint_dict.items():\n",
    "\n",
    "    for const_type in constraint:\n",
    "        for entity in constraint[const_type]:\n",
    "            entities.add(entity)\n",
    "entities = list(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting entities' hierarchy of superclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "def get_subclass_hierarchy(entity_id):\n",
    "      sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "      # SPARQL query to get all subclasses (direct and indirect) of the given entity\n",
    "      query = f\"\"\"\n",
    "      SELECT DISTINCT ?subclass ?subclassLabel WHERE {{\n",
    "          {{\n",
    "              wd:{entity_id} wdt:P31/wdt:P279* ?subclass.\n",
    "          }}\n",
    "            UNION\n",
    "          {{\n",
    "              wd:{entity_id} wdt:P279* ?subclass.\n",
    "          }}\n",
    "      }}\n",
    "      \"\"\"\n",
    "    # SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "\n",
    "      sparql.setQuery(query)\n",
    "      sparql.setReturnFormat(JSON)\n",
    "\n",
    "      results = sparql.query().convert()\n",
    "\n",
    "      subclass_hierarchy = []\n",
    "\n",
    "      for result in results[\"results\"][\"bindings\"]:\n",
    "          subclass_id = result[\"subclass\"][\"value\"].split(\"/\")[-1]\n",
    "          subclass_hierarchy.append(subclass_id)\n",
    "\n",
    "      return subclass_hierarchy\n",
    "\n",
    "ENTITY_2_HIERARCHY = {}\n",
    "for entity_id in tqdm(entities):\n",
    "    hierarchy = get_subclass_hierarchy(entity_id)\n",
    "    ENTITY_2_HIERARCHY[entity_id] = hierarchy\n",
    "\n",
    "len(ENTITY_2_HIERARCHY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = []\n",
    "for item in ENTITY_2_HIERARCHY.values():\n",
    "    ents.extend(item)\n",
    "len(set(ents)), len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaving only entity types that are used in constraints\n",
    "for entity in tqdm(ENTITY_2_HIERARCHY):\n",
    "    filtered_super_entities = [item for item in ENTITY_2_HIERARCHY[entity] if item in entities]\n",
    "    ENTITY_2_HIERARCHY[entity] = filtered_super_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = []\n",
    "for item in ENTITY_2_HIERARCHY.values():\n",
    "    ents.extend(item)\n",
    "len(set(ents)), len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR + 'entity_hierarchy.json', 'w') as f:\n",
    "    json.dump(ENTITY_2_HIERARCHY, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting entity types' labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "def fetch_labels(batch):\n",
    "    entity_values = \" \".join(f\"wd:{entity}\" for entity in batch)\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?entity ?entityLabel WHERE {{\n",
    "      VALUES ?entity {{ {entity_values} }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        return {\n",
    "            result[\"entity\"][\"value\"].split(\"/\")[-1]: result.get(\"entityLabel\", {}).get(\"value\", \"No label\")\n",
    "            for result in results[\"results\"][\"bindings\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error with batch {batch[:5]}...: {e}\")\n",
    "        return {}\n",
    "\n",
    "ENTITY_2_LABEL = {}\n",
    "\n",
    "for i in range(0, len(entities), BATCH_SIZE):\n",
    "    batch = entities[i:i + BATCH_SIZE]\n",
    "    print(f\"Processing batch {i // BATCH_SIZE + 1}/{(len(entities) // BATCH_SIZE) + 1}\")\n",
    "    \n",
    "    labels = fetch_labels(batch)\n",
    "    ENTITY_2_LABEL.update(labels)\n",
    "    \n",
    "# for entity, label in all_labels.items():\n",
    "#     print(f\"{entity}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ENTITY_2_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ENTITY_2_LABEL.keys())), len(set(ENTITY_2_LABEL.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2entity = {}\n",
    "for entity, label in ENTITY_2_LABEL.items():\n",
    "    if label not in label2entity:\n",
    "        label2entity[label] = []\n",
    "    label2entity[label].append(entity)\n",
    "\n",
    "for label, entities in label2entity.items():\n",
    "    if len(entities) > 1:\n",
    "        print(label, entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting descriptions for entity types with duplicated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "def get_entity_info(entity_id):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?entityLabel ?entityDescription WHERE {{\n",
    "      wd:{entity_id} rdfs:label ?entityLabel .\n",
    "      wd:{entity_id} schema:description ?entityDescription .\n",
    "      FILTER (lang(?entityLabel) = \"en\")\n",
    "      FILTER (lang(?entityDescription) = \"en\")\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    if results[\"results\"][\"bindings\"]:\n",
    "        result = results[\"results\"][\"bindings\"][0]\n",
    "        return {\n",
    "            \"label\": result[\"entityLabel\"][\"value\"],\n",
    "            \"description\": result[\"entityDescription\"][\"value\"]\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "for label, entities in label2entity.items():\n",
    "    if len(entities) > 1:\n",
    "        for entity_id in entities:\n",
    "            info = get_entity_info(entity_id)\n",
    "            ENTITY_2_LABEL[entity_id] = info['label'] + \" (\" + info['description'] +\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(ENTITY_2_LABEL.keys())), len(set(ENTITY_2_LABEL.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting entity types' aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "def get_entity_aliases(entity_id):\n",
    "    chinese_japanese_pattern = re.compile(r\"[\\u4E00-\\u9FFF\\u3400-\\u4DBF\\uF900-\\uFAFF\\u3040-\\u309F\\u30A0-\\u30FF\\u31F0-\\u31FF\\uFF00-\\uFFEF]\")\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?alias WHERE {{\n",
    "      wd:{entity_id} skos:altLabel ?alias .\n",
    "      FILTER (lang(?alias) = \"en\")\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    aliases = []\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "\n",
    "        alias = result[\"alias\"][\"value\"]\n",
    "        if not chinese_japanese_pattern.search(alias):\n",
    "          aliases.append(alias)\n",
    "        # except Exception as e:\n",
    "        #    continue\n",
    "    \n",
    "    return aliases\n",
    "\n",
    "ENTITY_2_ALIASES = {}\n",
    "for entity_id in tqdm(ENTITY_2_LABEL.keys()):\n",
    "    ENTITY_2_ALIASES[entity_id] = get_entity_aliases(entity_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(ENTITY_2_LABEL[ent], aliases) for ent, aliases in ENTITY_2_ALIASES.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_2_LABEL[\"Q186408\"], get_entity_aliases(\"Q186408\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_2_LABEL[\"Q309314\"], get_entity_aliases(\"Q309314\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building inverse mapping - object/subject type constraint to relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that relations with 'point in time' and 'quantity' data types don't have other constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prop, data_type in PROP_2_DATA_TYPE.items():\n",
    "#     if data_type == \"Quantity\":    \n",
    "#         val_constraints = [ENTITY_2_LABEL[ent] for ent in constraint_dict[prop][\"Value-type constraint\"]]\n",
    "#         subj_constraints = [ENTITY_2_LABEL[ent] for ent in constraint_dict[prop][\"Subject type constraint\"]]            \n",
    "#         # print(PROP_2_LABEL[prop], subj_constraints, val_constraints)\n",
    "#         assert len(val_constraints) == 0\n",
    "#         # no value constraints for data type quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prop, data_type in PROP_2_DATA_TYPE.items():\n",
    "#     if data_type == \"Point in time\":    \n",
    "#         val_constraints = [ENTITY_2_LABEL[ent] for ent in constraint_dict[prop][\"Value-type constraint\"]]\n",
    "#         subj_constraints = [ENTITY_2_LABEL[ent] for ent in constraint_dict[prop][\"Subject type constraint\"]]            \n",
    "#         # print(PROP_2_LABEL[prop], subj_constraints, val_constraints)\n",
    "#         assert len(val_constraints) == 0\n",
    "#         # no value constraints for data type quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj2prop_constraints = {\"<ANY SUBJECT>\": []}\n",
    "# Q309314 - quantity, Q186408 -  point in time \n",
    "obj2prop_constraint = {\"<ANY OBJECT>\": [], \"Q309314\": [], 'Q186408': []}\n",
    "\n",
    "for prop, constraint in constraint_dict.items():\n",
    "\n",
    "    if PROP_2_DATA_TYPE[prop] == \"Point in time\":\n",
    "        obj2prop_constraint['Q186408'].append(prop)\n",
    "    \n",
    "    elif PROP_2_DATA_TYPE[prop] == 'Quantity':\n",
    "        obj2prop_constraint['Q309314'].append(prop)\n",
    "    \n",
    "    elif constraint[\"Value-type constraint\"] == ['ANY']:\n",
    "        obj2prop_constraint[\"<ANY OBJECT>\"].append(prop)\n",
    "    \n",
    "    else:\n",
    "        for entity in constraint[\"Value-type constraint\"]:\n",
    "            if entity not in obj2prop_constraint:\n",
    "                obj2prop_constraint[entity] = []\n",
    "            obj2prop_constraint[entity].append(prop)\n",
    "\n",
    "    \n",
    "    if constraint[\"Subject type constraint\"] ==  ['ANY']:\n",
    "        subj2prop_constraints[\"<ANY SUBJECT>\"].append(prop)\n",
    "\n",
    "    else:\n",
    "        for entity in constraint[\"Subject type constraint\"]:\n",
    "            if entity not in subj2prop_constraints:\n",
    "                subj2prop_constraints[entity] = []\n",
    "            subj2prop_constraints[entity].append(prop)\n",
    "\n",
    "\n",
    "len(subj2prop_constraints), len(obj2prop_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+\"subj_constraint2prop.json\", 'w') as f:\n",
    "    json.dump(subj2prop_constraints, f)\n",
    "\n",
    "with open(ONTOLOGY_MAPPINGS_DIR+\"obj_constraint2prop.json\", 'w') as f:\n",
    "    json.dump(obj2prop_constraint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+'entity_type2label.json', 'w') as f:\n",
    "    json.dump(ENTITY_2_LABEL, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+'prop2aliases.json', 'w') as f:\n",
    "    json.dump(PROP2ALIASES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+'entity_type2aliases.json', 'w') as f:\n",
    "    json.dump(ENTITY_2_ALIASES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ONTOLOGY_MAPPINGS_DIR+'entity_type2hierarchy.json', 'w') as f:\n",
    "    json.dump(ENTITY_2_HIERARCHY, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
